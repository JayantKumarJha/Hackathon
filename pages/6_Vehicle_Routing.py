# -*- coding: utf-8 -*-
"""Vehicle Routing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9ztH5QuwTYeM4UtdpkCCVRDmYAC0t_M
"""

# app/pages/6_ðŸšš_Bin_Packing_&_Routing.py

# pages/6_Vehicle_Routing.py
import streamlit as st
import pandas as pd
import numpy as np
import folium
from streamlit_folium import st_folium
import requests
import time, math, warnings
from ortools.constraint_solver import routing_enums_pb2, pywrapcp

warnings.filterwarnings('ignore')

# --------------------------
# Streamlit Page 6 â€” Bin Packing + Vehicle Routing (with Geoapify Autocomplete)
# --------------------------

st.set_page_config(layout='wide')
st.title("Page 6 â€” Bin Packing + Vehicle Routing (VRP)")
st.markdown(
    "Upload your vehicle & item files, assign coordinates to locations and depot using Geoapify autocomplete, "
    "run packing and routing, and visualise the routes."
)

# --------------------------
# Config: where to get Geoapify key
# - Preferred: put in Streamlit secrets as [geoapify] api_key = \"YOUR_KEY\"
# - Fallback: enter manually in the textbox below (not recommended for production)
# --------------------------

def get_geoapify_key():
    # preferred: use st.secrets
    try:
        api_key = st.secrets["geoapify"]["api_key"]
        if api_key and isinstance(api_key, str):
            return api_key
    except Exception:
        pass
    # fallback: manual entry
    return st.text_input("Geoapify API key (or store it in Streamlit Secrets)", type="password")

GEOAPIFY_KEY = get_geoapify_key()
if not GEOAPIFY_KEY:
    st.warning("Geoapify API key required. Add it in Streamlit Secrets or paste in the input above.")
    st.stop()

# --------------------------
# Helpers
# --------------------------

def clean_item_columns(df: pd.DataFrame) -> pd.DataFrame:
    mapping = {
        'location id': ['location id', 'Location ID', 'location_id', 'LocationId', 'loc_id'],
        'id': ['id', 'ID', 'item_id', 'Item ID'],
        'type': ['type', 'Type', 'item_type'],
        'length': ['length', 'Length'],
        'width': ['width', 'Width'],
        'height': ['height', 'Height'],
        'weight': ['weight', 'Weight'],
        'quantity': ['quantity', 'Quantity', 'qty'],
        'stackable': ['stackable', 'Stackable'],
        'maxStack': ['maxStack', 'MaxStack', 'max_stack', 'Max Stack']
    }
    for correct, variants in mapping.items():
        for v in variants:
            if v in df.columns and correct not in df.columns:
                df = df.rename(columns={v: correct})
    return df


def haversine_distance(lat1, lon1, lat2, lon2):
    R = 6371000
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))


def ensure_session_state(key, default):
    if key not in st.session_state:
        st.session_state[key] = default


# --------------------------
# Geoapify API calls (cached)
# --------------------------

@st.cache_data(show_spinner=False)
def geoapify_autocomplete(query: str, api_key: str, limit: int = 6):
    """Return a list of candidate dicts from Geoapify autocomplete endpoint."""
    if not query or not api_key:
        return []
    url = "https://api.geoapify.com/v1/geocode/autocomplete"
    params = {"text": query, "limit": limit, "apiKey": api_key}
    try:
        r = requests.get(url, params=params, timeout=8)
        r.raise_for_status()
        data = r.json()
        results = data.get("results", [])
        candidates = []
        for res in results:
            # Each result provides lat, lon and formatted address
            candidates.append({
                "formatted": res.get("formatted", res.get("display_name", "")),
                "lat": res.get("lat"),
                "lon": res.get("lon"),
                "country": res.get("country"),
                "city": res.get("city") or res.get("county") or res.get("state")
            })
        return candidates
    except Exception:
        # On error return empty list (caller will show message)
        return []


@st.cache_data(show_spinner=False)
def geoapify_forward_search(query: str, api_key: str, limit: int = 1):
    """Return the best candidate from Geoapify forward geocode search."""
    if not query or not api_key:
        return None
    url = "https://api.geoapify.com/v1/geocode/search"
    params = {"text": query, "limit": limit, "apiKey": api_key}
    try:
        r = requests.get(url, params=params, timeout=8)
        r.raise_for_status()
        data = r.json()
        results = data.get("results", [])
        if not results:
            return None
        res = results[0]
        return {"formatted": res.get("formatted", res.get("display_name", "")), "lat": res.get("lat"), "lon": res.get("lon")}
    except Exception:
        return None


# --------------------------
# UI: Upload
# --------------------------
col1, col2 = st.columns([1, 1])
with col1:
    veh_file = st.file_uploader("Vehicle file (CSV or XLSX)", type=['csv', 'xlsx'], key='veh')
with col2:
    item_file = st.file_uploader("Items file (CSV or XLSX)", type=['csv', 'xlsx'], key='itm')

if not (veh_file and item_file):
    st.info("Upload both vehicle and item files to proceed. Example columns described in the original Colab code are expected.")
    st.stop()

# --------------------------
# Load Data
# --------------------------
try:
    if veh_file.name.endswith('.csv'):
        vehicle_df = pd.read_csv(veh_file)
    else:
        vehicle_df = pd.read_excel(veh_file)

    if item_file.name.endswith('.csv'):
        item_df = pd.read_csv(item_file)
    else:
        item_df = pd.read_excel(item_file)
except Exception as e:
    st.error(f"Failed to read uploaded files: {e}")
    st.stop()

# Clean headers
vehicle_df.columns = vehicle_df.columns.str.strip()
item_df.columns = item_df.columns.str.strip()
item_df = clean_item_columns(item_df)

# Ensure required columns exist
required = ['location id','id','type','length','width','height','weight','quantity','stackable','maxStack']
missing = [c for c in required if c not in item_df.columns]
if missing:
    st.error("Items file is missing required columns: " + ", ".join(missing))
    st.stop()

# Quick preview
st.subheader("Preview data")
st.write("Vehicles (first 50 rows):")
st.dataframe(vehicle_df.head(50))
st.write("Items (first 50 rows):")
st.dataframe(item_df.head(50))

# ---------- Units ----------
st.subheader("Units & conversion")
LENGTH_UNIT = st.selectbox("Select length unit used in your items file", options=['mm','cm','m'], index=0)
UNIT_CONVERSION = {'mm': 1/1000.0, 'cm': 1/100.0, 'm': 1.0}
conv = UNIT_CONVERSION[LENGTH_UNIT]
st.info(f"Converting lengths to metres using factor {conv}")

# Cast types
item_df['stackable'] = item_df['stackable'].astype(str).str.upper().isin(['TRUE','1','YES','Y'])
item_df['quantity'] = item_df['quantity'].astype(int)
if 'count' in vehicle_df.columns:
    vehicle_df['count'] = vehicle_df['count'].astype(int)
else:
    # assume 1 of each vehicle row if missing
    vehicle_df['count'] = 1

# --------------------------
# Location assignment (autocomplete UI for each location)
# --------------------------
st.subheader("Assign coordinates to each location and DEPOT (Geoapify autocomplete)")

unique_locs = sorted(item_df['location id'].unique().tolist())
ensure_session_state('location_coords', {})
ensure_session_state('location_names', {})

st.markdown(
    "For each Location ID: type a place/address fragment and click **Suggest** â†’ choose the best match from the dropdown â†’ click **Use selection**."
)
st.markdown("This uses Geoapify autocomplete and caches results to avoid repeated API calls.")

for lid in unique_locs:
    with st.expander(f"Location: {lid}", expanded=False):
        # current values
        current = st.session_state['location_coords'].get(lid, None)
        current_name = st.session_state['location_names'].get(lid, "")
        col_a, col_b = st.columns([3, 1])
        with col_a:
            query_key = f"query_{lid}"
            query_val = st.text_input(f"Type address/place for {lid}", value=current_name or "", key=query_key)
        with col_b:
            if st.button("Suggest", key=f"suggest_{lid}"):
                # call cached autocomplete
                suggestions = geoapify_autocomplete(query_val, GEOAPIFY_KEY, limit=8)
                if not suggestions:
                    st.warning("No suggestions found or API error. Try a different query.")
                    st.session_state[f"suggestions_{lid}"] = []
                else:
                    st.session_state[f"suggestions_{lid}"] = suggestions

        # show select box if suggestions exist
        suggestions = st.session_state.get(f"suggestions_{lid}", [])
        if suggestions:
            options = [f"{s['formatted']} ({s['lat']:.6f},{s['lon']:.6f})" for s in suggestions]
            sel_index = st.selectbox("Choose match", options=options, key=f"select_{lid}")
            # show a preview & a button to use selection
            if st.button("Use selection", key=f"use_{lid}"):
                # find selected item
                idx = options.index(sel_index)
                sel = suggestions[idx]
                st.session_state['location_coords'][lid] = (float(sel['lat']), float(sel['lon']))
                st.session_state['location_names'][lid] = sel['formatted']
                st.success(f"Assigned {lid} â†’ {sel['formatted']} ({sel['lat']:.6f}, {sel['lon']:.6f})")
                # clear suggestions for cleanliness
                st.session_state[f"suggestions_{lid}"] = []

        # quick show current coordinates
        if lid in st.session_state['location_coords']:
            lat, lon = st.session_state['location_coords'][lid]
            st.write(f"Coordinates â€” lat: {lat:.6f}, lon: {lon:.6f}")

# DEPOT
with st.expander("DEPOT (required)"):
    dep_key = "query_DEPOT"
    dep_query = st.text_input("Type address/place for DEPOT", value=st.session_state['location_names'].get('DEPOT',''), key=dep_key)
    if st.button("Suggest DEPOT", key="suggest_DEPOT"):
        suggestions = geoapify_autocomplete(dep_query, GEOAPIFY_KEY, limit=8)
        if not suggestions:
            st.warning("No suggestions found or API error. Try a different query.")
            st.session_state["suggestions_DEPOT"] = []
        else:
            st.session_state["suggestions_DEPOT"] = suggestions

    suggestions = st.session_state.get("suggestions_DEPOT", [])
    if suggestions:
        options = [f"{s['formatted']} ({s['lat']:.6f},{s['lon']:.6f})" for s in suggestions]
        sel_index = st.selectbox("Choose DEPOT match", options=options, key="select_DEPOT")
        if st.button("Use selection for DEPOT", key="use_DEPOT"):
            idx = options.index(sel_index)
            sel = suggestions[idx]
            st.session_state['location_coords']['DEPOT'] = (float(sel['lat']), float(sel['lon']))
            st.session_state['location_names']['DEPOT'] = sel['formatted']
            st.success(f"Assigned DEPOT â†’ {sel['formatted']} ({sel['lat']:.6f}, {sel['lon']:.6f})")
            st.session_state["suggestions_DEPOT"] = []

    if 'DEPOT' in st.session_state['location_coords']:
        lat, lon = st.session_state['location_coords']['DEPOT']
        st.write(f"Depot coords â€” lat: {lat:.6f}, lon: {lon:.6f}")

# Check coordinates exist
missing_coords = [l for l in unique_locs if l not in st.session_state['location_coords']]
if 'DEPOT' not in st.session_state['location_coords']:
    st.warning("Please set coordinates for the DEPOT to continue.")
    st.stop()
if missing_coords:
    st.warning(f"Coordinates missing for locations: {missing_coords}. Please assign them to continue.")
    st.stop()

# Show map with all points
st.subheader("Locations map")
all_coords = list(st.session_state['location_coords'].values())
all_lats = [c[0] for c in all_coords]
all_lons = [c[1] for c in all_coords]
center_lat = float(np.mean(all_lats))
center_lon = float(np.mean(all_lons))
map_object = folium.Map(location=[center_lat, center_lon], zoom_start=8, tiles='CartoDB positron')
for lid, (lat, lon) in st.session_state['location_coords'].items():
    popup_html = f"{lid}: {st.session_state['location_names'].get(lid,'')}"
    folium.Marker([lat, lon], popup=popup_html, tooltip=str(lid)).add_to(map_object)
st_folium(map_object, width=900, height=500)

# --------------------------
# Build distance matrix (Haversine) & pack-units
# --------------------------
st.subheader("Build distance matrix & expand items into pack-units")
loc_ids = sorted([k for k in st.session_state['location_coords'].keys() if k != 'DEPOT'])
all_ids = loc_ids + ['DEPOT']
coords = [st.session_state['location_coords'][lid] for lid in all_ids]
N = len(coords)

dist_mat = np.zeros((N,N), dtype=np.int64)
for i in range(N):
    lat1, lon1 = coords[i]
    for j in range(N):
        lat2, lon2 = coords[j]
        dist_mat[i,j] = int(haversine_distance(lat1, lon1, lat2, lon2))

st.write(f"Distance matrix built for {N} nodes (meters)")

# Expand items to pack units
pack_units = []
for _, row in item_df.iterrows():
    loc = row['location id']
    item_id = row['id']
    L = float(row['length']) * conv
    W = float(row['width']) * conv
    H = float(row['height']) * conv
    weight = float(row['weight'])
    qty = int(row['quantity'])
    stackable = bool(row['stackable'])
    max_stack = int(row['maxStack']) if not pd.isna(row['maxStack']) else 1
    if stackable and max_stack > 1:
        fullstacks = qty // max_stack
        rem = qty % max_stack
        for _ in range(fullstacks):
            pack_units.append({'location id': loc, 'item_id': item_id, 'length_m': L, 'width_m': W, 'height_m': H * max_stack, 'weight_kg': weight * max_stack, 'count': max_stack})
        if rem > 0:
            pack_units.append({'location id': loc, 'item_id': item_id, 'length_m': L, 'width_m': W, 'height_m': H * rem, 'weight_kg': weight * rem, 'count': rem})
    else:
        for _ in range(qty):
            pack_units.append({'location id': loc, 'item_id': item_id, 'length_m': L, 'width_m': W, 'height_m': H, 'weight_kg': weight, 'count': 1})

pack_df = pd.DataFrame(pack_units)
pack_df['volume_m3'] = pack_df['length_m'] * pack_df['width_m'] * pack_df['height_m']
st.write(f"Created {len(pack_df)} pack-units from the items file")
st.dataframe(pack_df.head(50))

# --------------------------
# Instantiate vehicles
# --------------------------
st.subheader("Instantiate vehicle instances")
vehicle_instances = []
for _, v in vehicle_df.iterrows():
    v_count = int(v.get('count',1))
    for i in range(v_count):
        inst = {
            'vehicle_type': v.get('vehicle_id', f"veh_{_}"),
            'length_m': float(v['length']) * conv if 'length' in v else 0.0,
            'width_m': float(v['width']) * conv if 'width' in v else 0.0,
            'height_m': float(v['height']) * conv if 'height' in v else 0.0,
            'max_load_kg': float(v.get('max_load', v.get('max_load_kg', 0.0))),
            'id': f"{v.get('vehicle_id','veh')}_{i+1}"
        }
        inst['volume_m3'] = inst['length_m'] * inst['width_m'] * inst['height_m']
        vehicle_instances.append(inst)

if not vehicle_instances:
    st.error('No vehicle instances created. Check vehicle file columns (length,width,height,max_load,count)')
    st.stop()

st.write(f"Instantiated {len(vehicle_instances)} vehicle instances")
st.dataframe(pd.DataFrame(vehicle_instances))

# --------------------------
# Bin packing (greedy)
# --------------------------
st.subheader("Bin packing (assign packs to vehicles)")

vehicle_state = {v['id']:{'remaining_vol': v['volume_m3'],'remaining_wt': v['max_load_kg'],'vehicle':v,'assigned_packs':[]} for v in vehicle_instances}

grouped = pack_df.groupby('location id')
assignments = {}
for loc, group in grouped:
    packs = group.sort_values('volume_m3', ascending=False).to_dict('records')
    packs_left = packs.copy()
    def packs_total_volume_weight(packs_list):
        return sum(p['volume_m3'] for p in packs_list), sum(p['weight_kg'] for p in packs_list)
    vol_total, wt_total = packs_total_volume_weight(packs_left)
    single_candidate = None
    for vid, stt in vehicle_state.items():
        if stt['remaining_vol'] + 1e-9 >= vol_total and stt['remaining_wt'] + 1e-9 >= wt_total:
            single_candidate = vid
            break
    if single_candidate:
        vehicle_state[single_candidate]['assigned_packs'].extend([(loc, p) for p in packs_left])
        vehicle_state[single_candidate]['remaining_vol'] -= vol_total
        vehicle_state[single_candidate]['remaining_wt'] -= wt_total
        assignments.setdefault(single_candidate, []).append(loc)
        continue
    # greedy
    for p in packs_left:
        placed = False
        v_order = sorted(vehicle_state.items(), key=lambda kv: kv[1]['remaining_vol'], reverse=True)
        for vid, stt in v_order:
            if stt['remaining_vol'] + 1e-9 >= p['volume_m3'] and stt['remaining_wt'] + 1e-9 >= p['weight_kg']:
                stt['assigned_packs'].append((loc, p))
                stt['remaining_vol'] -= p['volume_m3']
                stt['remaining_wt'] -= p['weight_kg']
                assignments.setdefault(vid, []).append(loc)
                placed = True
                break
        if not placed:
            st.warning(f"Could not place pack for location {loc}, item {p['item_id']} (vol {p['volume_m3']:.3f}, wt {p['weight_kg']:.1f}).")

used_vehicles = [v for v in vehicle_state.values() if v['assigned_packs']]
st.write(f"Vehicles used: {len(used_vehicles)}")
for vid, stt in vehicle_state.items():
    if stt['assigned_packs']:
        assigned_locs = sorted(set([x[0] for x in stt['assigned_packs']]))
        used_vol = stt['vehicle']['volume_m3'] - stt['remaining_vol']
        used_wt = stt['vehicle']['max_load_kg'] - stt['remaining_wt']
        st.write(f"Vehicle {vid}: visits {assigned_locs}, used_vol={used_vol:.3f}m3, used_wt={used_wt:.1f}kg")

# --------------------------
# VRP: build model & solve
# --------------------------
st.subheader("Create VRP model and solve (OR-Tools)")

location_idx_map = {loc: i for i, loc in enumerate(all_ids)}
num_nodes = len(all_ids)

demand_weight = np.zeros(num_nodes, dtype=int)
demand_volume = np.zeros(num_nodes, dtype=int)

for vid, stt in vehicle_state.items():
    for loc, p in stt['assigned_packs']:
        idx = location_idx_map[loc]
        demand_weight[idx] += int(math.ceil(p['weight_kg']))
        demand_volume[idx] += int(math.ceil(p['volume_m3'] * 1000))

vehicle_ids = []
vehicle_cap_wt = []
vehicle_cap_vol = []
for vid, stt in vehicle_state.items():
    vehicle_ids.append(vid)
    vehicle_cap_wt.append(int(math.floor(stt['vehicle']['max_load_kg'])))
    vehicle_cap_vol.append(int(math.floor(stt['vehicle']['volume_m3'] * 1000)))

if len(vehicle_ids) == 0:
    st.error('No vehicles available for routing. Aborting')
    st.stop()

manager = pywrapcp.RoutingIndexManager(num_nodes, len(vehicle_ids), location_idx_map['DEPOT'])
routing = pywrapcp.RoutingModel(manager)

cost_matrix = dist_mat.tolist()

def distance_callback(i, j):
    ni = manager.IndexToNode(i)
    nj = manager.IndexToNode(j)
    return int(cost_matrix[ni][nj])

transit_callback_index = routing.RegisterTransitCallback(distance_callback)
routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)

def demand_weight_callback(index):
    node = manager.IndexToNode(index)
    return 0 if node == location_idx_map['DEPOT'] else int(demand_weight[node])

demand_wt_cb = routing.RegisterUnaryTransitCallback(demand_weight_callback)
routing.AddDimensionWithVehicleCapacity(demand_wt_cb, 0, vehicle_cap_wt, True, 'Weight')

def demand_vol_callback(index):
    node = manager.IndexToNode(index)
    return 0 if node == location_idx_map['DEPOT'] else int(demand_volume[node])

demand_vol_cb = routing.RegisterUnaryTransitCallback(demand_vol_callback)
routing.AddDimensionWithVehicleCapacity(demand_vol_cb, 0, vehicle_cap_vol, True, 'Volume')

search_params = pywrapcp.DefaultRoutingSearchParameters()
search_params.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC
search_params.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH
search_params.time_limit.seconds = 30

with st.spinner('Solving VRP...'):
    solution = routing.SolveWithParameters(search_params)

if not solution:
    st.error('No VRP solution found')
    st.stop()

solution_routes = {}
for v_idx, vid in enumerate(vehicle_ids):
    index = routing.Start(v_idx)
    route = []
    while not routing.IsEnd(index):
        node = manager.IndexToNode(index)
        if node != location_idx_map['DEPOT']:
            loc_id = all_ids[node]
            route.append(loc_id)
        index = solution.Value(routing.NextVar(index))
    solution_routes[vid] = route

st.success('Routing solved')
for v, r in solution_routes.items():
    if r:
        st.write(f"{v} -> {r}")

# --------------------------
# Visualization (folium)
# --------------------------
st.subheader("Route visualization")
all_lats = [st.session_state['location_coords']['DEPOT'][0]]
all_lons = [st.session_state['location_coords']['DEPOT'][1]]
for route_locs in solution_routes.values():
    for loc in route_locs:
        lat, lon = st.session_state['location_coords'][loc]
        all_lats.append(lat)
        all_lons.append(lon)
center_lat = float(np.mean(all_lats))
center_lon = float(np.mean(all_lons))

m = folium.Map(location=[center_lat, center_lon], zoom_start=7, tiles='CartoDB positron')

colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22']
for i, (veh, route_locs) in enumerate(solution_routes.items()):
    if not route_locs:
        continue
    color = colors[i % len(colors)]
    route_coords = [st.session_state['location_coords']['DEPOT']]
    for loc in route_locs:
        lat, lon = st.session_state['location_coords'][loc]
        route_coords.append((lat, lon))
        popup_text = f"{loc} ({lat:.4f}, {lon:.4f})\\nVehicle: {veh}"
        folium.CircleMarker(
            location=[lat, lon],
            radius=6,
            color=color,
            fill=True,
            fill_color=color,
            fill_opacity=0.9,
            popup=popup_text,
            tooltip=str(loc)
        ).add_to(m)
    route_coords.append(st.session_state['location_coords']['DEPOT'])
    folium.PolyLine(route_coords, color=color, weight=3, opacity=0.8).add_to(m)
    folium.map.Marker(
        route_coords[1],
        icon=folium.DivIcon(html=f"<div style='font-size:12pt;color:{color};font-weight:bold'>{veh}</div>")
    ).add_to(m)

# depot marker
dlat, dlon = st.session_state['location_coords']['DEPOT']
folium.Marker([dlat, dlon], popup="DEPOT", tooltip="DEPOT", icon=folium.Icon(color='black', icon='home')).add_to(m)

st_folium(m, width=900, height=600)

# --------------------------
# Export results
# --------------------------
st.subheader('Export results')
rows = []
for vid, stt in vehicle_state.items():
    for loc, p in stt['assigned_packs']:
        rows.append({'vehicle_id': vid, 'location': loc, 'item_id': p['item_id'], 'count': p['count'], 'weight_kg': p['weight_kg'], 'volume_m3': p['volume_m3']})
assign_df = pd.DataFrame(rows)
if not assign_df.empty:
    csv = assign_df.to_csv(index=False).encode('utf-8')
    st.download_button('Download assignments CSV', data=csv, file_name='assignments.csv', mime='text/csv')

st.info('Page 6 complete. You can copy this file into your Streamlit multipage app as the page module for the sidebar entry (Page 6).')


