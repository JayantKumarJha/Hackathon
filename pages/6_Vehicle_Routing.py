# -*- coding: utf-8 -*-
"""Vehicle Routing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9ztH5QuwTYeM4UtdpkCCVRDmYAC0t_M
"""

# app/pages/6_ðŸšš_Bin_Packing_&_Routing.py

# pages/6_Vehicle_Routing.py
import streamlit as st
import pandas as pd
import numpy as np
import folium
from streamlit_folium import st_folium
import math, warnings, requests, time
from ortools.constraint_solver import routing_enums_pb2, pywrapcp

warnings.filterwarnings('ignore')

st.set_page_config(layout='wide')
st.title("Page 6 â€” Bin Packing + Vehicle Routing (VRP)")
st.markdown("Upload your vehicle & item files, assign coordinates, run packing and routing, and visualize routes.")

# ---------- Helpers ----------
def clean_item_columns(df: pd.DataFrame) -> pd.DataFrame:
    mapping = {
        'location id': ['location id', 'Location ID', 'location_id', 'LocationId', 'loc_id'],
        'id': ['id', 'ID', 'item_id', 'Item ID'],
        'type': ['type', 'Type', 'item_type'],
        'length': ['length', 'Length'],
        'width': ['width', 'Width'],
        'height': ['height', 'Height'],
        'weight': ['weight', 'Weight'],
        'quantity': ['quantity', 'Quantity', 'qty'],
        'stackable': ['stackable', 'Stackable'],
        'maxStack': ['maxStack', 'MaxStack', 'max_stack', 'Max Stack']
    }
    for correct, variants in mapping.items():
        for v in variants:
            if v in df.columns and correct not in df.columns:
                df = df.rename(columns={v: correct})
    return df

def haversine_distance(lat1, lon1, lat2, lon2):
    R = 6371000
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))

def ensure_session_state(key, default):
    if key not in st.session_state:
        st.session_state[key] = default

# ---------- Manual refresh ----------
if 'manual_refresh' not in st.session_state:
    st.session_state['manual_refresh'] = True

if st.button("Manual Refresh"):
    st.session_state['manual_refresh'] = True
else:
    st.session_state['manual_refresh'] = False

if not st.session_state['manual_refresh']:
    st.stop()

# ---------- Upload ----------
col1, col2 = st.columns([1,1])
with col1:
    veh_file = st.file_uploader("Vehicle file (CSV/XLSX)", type=['csv','xlsx'])
with col2:
    item_file = st.file_uploader("Items file (CSV/XLSX)", type=['csv','xlsx'])

if not (veh_file and item_file):
    st.info("Upload both vehicle and item files to proceed.")
    st.stop()

# ---------- Load Data ----------
try:
    vehicle_df = pd.read_csv(veh_file) if veh_file.name.endswith('.csv') else pd.read_excel(veh_file)
    item_df = pd.read_csv(item_file) if item_file.name.endswith('.csv') else pd.read_excel(item_file)
except Exception as e:
    st.error(f"Failed to read files: {e}")
    st.stop()

vehicle_df.columns = vehicle_df.columns.str.strip()
item_df.columns = item_df.columns.str.strip()
item_df = clean_item_columns(item_df)

# Ensure required columns
required = ['location id','id','type','length','width','height','weight','quantity','stackable','maxStack']
missing = [c for c in required if c not in item_df.columns]
if missing:
    st.error("Items file missing required columns: " + ", ".join(missing))
    st.stop()

# ---------- Preview ----------
st.subheader("Preview Data")
st.write("Vehicles:")
st.dataframe(vehicle_df.head(50))
st.write("Items:")
st.dataframe(item_df.head(50))

# ---------- Units ----------
st.subheader("Units & Conversion")
LENGTH_UNIT = st.selectbox("Length unit", ['mm','cm','m'], index=0)
conv = {'mm':1/1000,'cm':1/100,'m':1}[LENGTH_UNIT]
st.info(f"Converting lengths to meters with factor {conv}")

# Cast types
item_df['stackable'] = item_df['stackable'].astype(str).str.upper().isin(['TRUE','1','YES','Y'])
item_df['quantity'] = item_df['quantity'].astype(int)
vehicle_df['count'] = vehicle_df['count'].astype(int) if 'count' in vehicle_df.columns else 1

# ---------- Geocoding using Geoapify ----------
st.subheader("Assign Coordinates")
ensure_session_state('location_coords', {})
ensure_session_state('location_names', {})

GEO_API_KEY = "YOUR_GEOAPIFY_API_KEY"  # <-- paste your key here

@st.cache_data(show_spinner=False)
def geoapify_suggest(query):
    try:
        r = requests.get(
            "https://api.geoapify.com/v1/geocode/autocomplete",
            params={"text": query, "limit": 5, "apiKey": GEO_API_KEY, "type": "city"}
        )
        data = r.json()
        if 'features' in data:
            return [(f"{f['properties'].get('city','')}, {f['properties'].get('state','')}, {f['properties'].get('country','')}",
                     f['properties']['lat'], f['properties']['lon']) for f in data['features']]
        return []
    except Exception as e:
        return []

unique_locs = sorted(item_df['location id'].unique())
unique_locs_display = unique_locs.copy()

for lid in unique_locs_display + ['DEPOT']:
    with st.expander(f"Location: {lid}", expanded=True):
        name = st.session_state['location_names'].get(lid,'')
        query = st.text_input(f"Search {lid}", value=name, key=f"search_{lid}")
        suggestions = geoapify_suggest(query) if query else []
        for display, lat, lon in suggestions:
            if st.button(f"Select: {display}", key=f"sel_{lid}_{display}"):
                st.session_state['location_coords'][lid] = (lat, lon)
                st.session_state['location_names'][lid] = display
                st.success(f"Assigned {display}")

# Check coords
missing_coords = [l for l in unique_locs + ['DEPOT'] if l not in st.session_state['location_coords']]
if missing_coords:
    st.warning(f"Missing coordinates: {missing_coords}. Assign them to continue.")
    st.stop()

# ---------- Show Map ----------
st.subheader("Locations Map")
all_coords = list(st.session_state['location_coords'].values())
center_lat = np.mean([c[0] for c in all_coords])
center_lon = np.mean([c[1] for c in all_coords])
m = folium.Map(location=[center_lat, center_lon], zoom_start=6)
for lid, (lat, lon) in st.session_state['location_coords'].items():
    folium.Marker([lat, lon], popup=f"{lid}: {st.session_state['location_names'][lid]}").add_to(m)
st_folium(m, width=900, height=500)

# ---------- Distance matrix ----------
loc_ids = sorted([l for l in st.session_state['location_coords'].keys() if l!='DEPOT'])
all_ids = loc_ids + ['DEPOT']
coords = [st.session_state['location_coords'][lid] for lid in all_ids]
N = len(coords)
dist_mat = np.zeros((N,N), dtype=int)
for i,(lat1,lon1) in enumerate(coords):
    for j,(lat2,lon2) in enumerate(coords):
        dist_mat[i,j] = int(haversine_distance(lat1,lon1,lat2,lon2))

# ---------- Expand items ----------
pack_units = []
for _, row in item_df.iterrows():
    loc = row['location id']
    item_id = row['id']
    L = float(row['length']) * conv
    W = float(row['width']) * conv
    H = float(row['height']) * conv
    weight = float(row['weight'])
    qty = int(row['quantity'])
    stackable = bool(row['stackable'])
    max_stack = int(row['maxStack']) if not pd.isna(row['maxStack']) else 1
    if stackable and max_stack>1:
        fullstacks = qty//max_stack
        rem = qty%max_stack
        for _ in range(fullstacks):
            pack_units.append({'location id':loc,'item_id':item_id,'length_m':L,'width_m':W,'height_m':H*max_stack,'weight_kg':weight*max_stack,'count':max_stack})
        if rem>0:
            pack_units.append({'location id':loc,'item_id':item_id,'length_m':L,'width_m':W,'height_m':H*rem,'weight_kg':weight*rem,'count':rem})
    else:
        for _ in range(qty):
            pack_units.append({'location id':loc,'item_id':item_id,'length_m':L,'width_m':W,'height_m':H,'weight_kg':weight,'count':1})
pack_df = pd.DataFrame(pack_units)
pack_df['volume_m3'] = pack_df['length_m']*pack_df['width_m']*pack_df['height_m']

# ---------- Instantiate vehicles ----------
vehicle_instances = []
for _, v in vehicle_df.iterrows():
    for i in range(int(v.get('count',1))):
        inst = {
            'vehicle_type': v.get('vehicle_type', v.get('vehicle_id', f"veh_{_}")),
            'length_m': float(v.get('length',0))*conv,
            'width_m': float(v.get('width',0))*conv,
            'height_m': float(v.get('height',0))*conv,
            'max_load_kg': float(v.get('max_load', v.get('max_load_kg',0))),
            'id': f"{v.get('vehicle_type', v.get('vehicle_id','veh'))}_{i+1}"
        }
        inst['volume_m3'] = inst['length_m']*inst['width_m']*inst['height_m']
        vehicle_instances.append(inst)
if not vehicle_instances:
    st.error("No vehicles instantiated"); st.stop()

# ---------- Bin packing (multi-vehicle split) ----------
st.subheader("Bin Packing Assignments")
vehicle_state = {v['id']:{'remaining_vol':v['volume_m3'],'remaining_wt':v['max_load_kg'],'vehicle':v,'assigned_packs':[]} for v in vehicle_instances}
for p in pack_df.to_dict('records'):
    qty_left = p['count']
    while qty_left>0:
        placed=False
        v_order = sorted(vehicle_state.items(), key=lambda kv: kv[1]['remaining_vol'], reverse=True)
        for vid, stt in v_order:
            cap_count = min(qty_left,
                            int(stt['remaining_vol']/p['volume_m3']) if p['volume_m3']>0 else qty_left,
                            int(stt['remaining_wt']/p['weight_kg']) if p['weight_kg']>0 else qty_left)
            if cap_count>0:
                stt['assigned_packs'].append((p['location id'], {**p,'count':cap_count}))
                stt['remaining_vol']-=p['volume_m3']*cap_count
                stt['remaining_wt']-=p['weight_kg']*cap_count
                qty_left-=cap_count
                placed=True
                break
        if not placed:
            st.warning(f"Item {p['item_id']} at {p['location id']} too big for any vehicle. Qty left: {qty_left}")
            break

# ---------- VRP ----------
st.subheader("VRP Model & Solution")
location_idx_map = {loc:i for i, loc in enumerate(all_ids)}
num_nodes = len(all_ids)
demand_weight = np.zeros(num_nodes, dtype=int)
demand_volume = np.zeros(num_nodes, dtype=int)
for stt in vehicle_state.values():
    for loc, p in stt['assigned_packs']:
        idx = location_idx_map[loc]
        demand_weight[idx]+=int(math.ceil(p['weight_kg']))
        demand_volume[idx]+=int(math.ceil(p['volume_m3']*1000))
vehicle_ids = list(vehicle_state.keys())
vehicle_cap_wt = [int(stt['vehicle']['max_load_kg']) for stt in vehicle_state.values()]
vehicle_cap_vol=[int(stt['vehicle']['volume_m3']*1000) for stt in vehicle_state.values()]

manager = pywrapcp.RoutingIndexManager(num_nodes,len(vehicle_ids),location_idx_map['DEPOT'])
routing = pywrapcp.RoutingModel(manager)
cost_matrix = dist_mat.tolist()
def distance_callback(i,j):
    return int(cost_matrix[manager.IndexToNode(i)][manager.IndexToNode(j)])
transit_cb_idx = routing.RegisterTransitCallback(distance_callback)
routing.SetArcCostEvaluatorOfAllVehicles(transit_cb_idx)
# Weight dimension
def demand_wt_cb(idx):
    node=manager.IndexToNode(idx)
    return 0 if node==location_idx_map['DEPOT'] else int(demand_weight[node])
routing.AddDimensionWithVehicleCapacity(routing.RegisterUnaryTransitCallback(demand_wt_cb),0,vehicle_cap_wt,True,'Weight')
# Volume dimension
def demand_vol_cb(idx):
    node=manager.IndexToNode(idx)
    return 0 if node==location_idx_map['DEPOT'] else int(demand_volume[node])
routing.AddDimensionWithVehicleCapacity(routing.RegisterUnaryTransitCallback(demand_vol_cb),0,vehicle_cap_vol,True,'Volume')
# Solve
search_params = pywrapcp.DefaultRoutingSearchParameters()
search_params.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC
search_params.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH
search_params.time_limit.seconds = 30
solution = routing.SolveWithParameters(search_params)
if not solution:
    st.error("No VRP solution found"); st.stop()

# ---------- Extract routes + distances ----------
solution_routes = {}
total_distance = {}
for v_idx, vid in enumerate(vehicle_ids):
    index = routing.Start(v_idx)
    route=[]
    dist=0
    while not routing.IsEnd(index):
        node=manager.IndexToNode(index)
        if node!=location_idx_map['DEPOT']:
            route.append(all_ids[node])
        next_index = solution.Value(routing.NextVar(index))
        dist+=routing.GetArcCostForVehicle(index,next_index,v_idx)
        index=next_index
    solution_routes[vid]=route
    total_distance[vid]=dist

st.success("Routing solved")
for vid,r in solution_routes.items():
    st.write(f"{vid}: Route {r}, Distance {total_distance[vid]/1000:.2f} km")

# ---------- Map Visualization with vehicle-type coloring ----------
st.subheader("Route Map")
m = folium.Map(location=[np.mean([c[0] for c in coords]),np.mean([c[1] for c in coords])], zoom_start=6)
vehicle_types = list({v['vehicle_type'] for v in vehicle_instances})
type_colors = {vtype: color for vtype, color in zip(vehicle_types, ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2','#7f7f7f','#bcbd22'])}
for i,(vid,route_locs) in enumerate(solution_routes.items()):
    color = type_colors[vehicle_state[vid]['vehicle']['vehicle_type']]
    route_coords=[st.session_state['location_coords']['DEPOT']]
    for loc in route_locs:
        lat,lon=st.session_state['location_coords'][loc]
        route_coords.append((lat,lon))
        folium.CircleMarker(location=[lat,lon],radius=6,color=color,fill=True,fill_color=color,fill_opacity=0.9,
                            popup=f"{loc}\nVehicle: {vid}",tooltip=str(loc)).add_to(m)
    route_coords.append(st.session_state['location_coords']['DEPOT'])
    folium.PolyLine(route_coords,color=color,weight=3,opacity=0.8).add_to(m)
st_folium(m,width=900,height=600)

# ---------- Download ----------
st.subheader("Export Results")
rows=[]
for vid, stt in vehicle_state.items():
    for loc, p in stt['assigned_packs']:
        rows.append({'vehicle_id':vid,'location':loc,'item_id':p['item_id'],'count':p['count'],'weight_kg':p['weight_kg'],'volume_m3':p['volume_m3']})
assign_df=pd.DataFrame(rows)
if not assign_df.empty:
    csv=assign_df.to_csv(index=False).encode('utf-8')
    st.download_button("Download CSV",data=csv,file_name='assignments.csv',mime='text/csv')

