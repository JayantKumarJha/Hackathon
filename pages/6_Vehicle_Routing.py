# -*- coding: utf-8 -*-
"""Vehicle Routing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9ztH5QuwTYeM4UtdpkCCVRDmYAC0t_M
"""

# app/pages/6_ðŸšš_Bin_Packing_&_Routing.py

# pages/6_Vehicle_Routing.py
import streamlit as st
import pandas as pd
import numpy as np
import folium
from streamlit_folium import st_folium
import requests
import math, warnings
from ortools.constraint_solver import routing_enums_pb2, pywrapcp

warnings.filterwarnings('ignore')

st.set_page_config(layout='wide')
st.title("Page 6 â€” Bin Packing + Vehicle Routing (VRP)")

# -------------------------- Helpers --------------------------
def clean_item_columns(df: pd.DataFrame) -> pd.DataFrame:
    mapping = {
        'location id': ['location id', 'Location ID', 'location_id', 'LocationId', 'loc_id'],
        'id': ['id', 'ID', 'item_id', 'Item ID'],
        'type': ['type', 'Type', 'item_type'],
        'length': ['length', 'Length'],
        'width': ['width', 'Width'],
        'height': ['height', 'Height'],
        'weight': ['weight', 'Weight'],
        'quantity': ['quantity', 'Quantity', 'qty'],
        'stackable': ['stackable', 'Stackable'],
        'maxStack': ['maxStack', 'MaxStack', 'max_stack', 'Max Stack']
    }
    for correct, variants in mapping.items():
        for v in variants:
            if v in df.columns and correct not in df.columns:
                df = df.rename(columns={v: correct})
    return df

def haversine_distance(lat1, lon1, lat2, lon2):
    R = 6371000
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))

def ensure_session_state(key, default):
    if key not in st.session_state:
        st.session_state[key] = default

# -------------------------- Geoapify --------------------------
GEOAPIFY_KEY = st.secrets["geoapify"]["api_key"]

@st.cache_data(ttl=3600)
def geoapify_autocomplete(query, limit=5):
    if not query.strip():
        return []
    url = "https://api.geoapify.com/v1/geocode/autocomplete"
    params = {"text": query, "limit": limit, "apiKey": GEOAPIFY_KEY}
    try:
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json()
        results = []
        for f in data.get("features", []):
            props = f.get("properties", {})
            results.append({
                "name": props.get("formatted") or props.get("city") or query,
                "lat": props.get("lat"),
                "lon": props.get("lon")
            })
        return results
    except Exception as e:
        st.error(f"Geoapify API error: {e}")
        return []

# -------------------------- File Upload --------------------------
col1, col2 = st.columns(2)
with col1:
    veh_file = st.file_uploader("Vehicle file (CSV/XLSX)", type=['csv','xlsx'])
with col2:
    item_file = st.file_uploader("Items file (CSV/XLSX)", type=['csv','xlsx'])

if not (veh_file and item_file):
    st.info("Upload both vehicle and item files to proceed.")
    st.stop()

try:
    vehicle_df = pd.read_csv(veh_file) if veh_file.name.endswith('.csv') else pd.read_excel(veh_file)
    item_df = pd.read_csv(item_file) if item_file.name.endswith('.csv') else pd.read_excel(item_file)
except Exception as e:
    st.error(f"Failed to read uploaded files: {e}")
    st.stop()

vehicle_df.columns = vehicle_df.columns.str.strip()
item_df.columns = item_df.columns.str.strip()
item_df = clean_item_columns(item_df)

required = ['location id','id','type','length','width','height','weight','quantity','stackable','maxStack']
missing = [c for c in required if c not in item_df.columns]
if missing:
    st.error("Items file is missing required columns: " + ", ".join(missing))
    st.stop()

# -------------------------- Units --------------------------
st.subheader("Units & conversion")
LENGTH_UNIT = st.selectbox("Select length unit", ['mm','cm','m'], index=0)
UNIT_CONVERSION = {'mm':1/1000.0,'cm':1/100.0,'m':1.0}
conv = UNIT_CONVERSION[LENGTH_UNIT]
item_df['stackable'] = item_df['stackable'].astype(str).str.upper().isin(['TRUE','1','YES','Y'])
item_df['quantity'] = item_df['quantity'].astype(int)
vehicle_df['count'] = vehicle_df.get('count',1).astype(int) if 'count' in vehicle_df.columns else 1

# -------------------------- Location Assignment --------------------------
st.subheader("Assign coordinates to each location and DEPOT")
unique_locs = sorted(item_df['location id'].unique())
ensure_session_state('location_coords', {})
ensure_session_state('location_names', {})

for lid in unique_locs:
    with st.expander(f"Location: {lid}", expanded=False):
        coords = st.session_state['location_coords'].get(lid,None)
        name = st.session_state['location_names'].get(lid,'')
        query = st.text_input(f"Search address for {lid}", value=name, key=f"search_{lid}")
        if st.button(f"Geocode {lid}", key=f"geocode_{lid}"):
            results = geoapify_autocomplete(query)
            if results:
                lat, lon = results[0]['lat'], results[0]['lon']
                st.session_state['location_coords'][lid] = (lat, lon)
                st.session_state['location_names'][lid] = results[0]['name']
                st.success(f"Found: {results[0]['name']} ({lat:.4f}, {lon:.4f})")
            else:
                st.warning("No suggestions found or API error. Try a different query.")
        if lid in st.session_state['location_coords']:
            lat, lon = st.session_state['location_coords'][lid]
            st.write(f"Coordinates â€” lat: {lat:.6f}, lon: {lon:.6f}")

with st.expander("DEPOT (required)"):
    dep_query = st.text_input("Search address for DEPOT", value=st.session_state['location_names'].get('DEPOT',''), key='search_DEPOT')
    if st.button("Geocode DEPOT", key='geocode_DEPOT'):
        results = geoapify_autocomplete(dep_query)
        if results:
            lat, lon = results[0]['lat'], results[0]['lon']
            st.session_state['location_coords']['DEPOT'] = (lat, lon)
            st.session_state['location_names']['DEPOT'] = results[0]['name']
            st.success(f"Depot: {results[0]['name']} ({lat:.4f}, {lon:.4f})")
        else:
            st.warning("No suggestions found or API error for DEPOT.")
    if 'DEPOT' in st.session_state['location_coords']:
        lat, lon = st.session_state['location_coords']['DEPOT']
        st.write(f"Depot coords â€” lat: {lat:.6f}, lon: {lon:.6f}")

missing_coords = [l for l in unique_locs if l not in st.session_state['location_coords']]
if 'DEPOT' not in st.session_state['location_coords'] or missing_coords:
    st.warning(f"Coordinates missing for: {missing_coords + ['DEPOT'] if 'DEPOT' not in st.session_state['location_coords'] else missing_coords}")
    st.stop()

# -------------------------- Map --------------------------
st.subheader("Locations map")
all_coords = list(st.session_state['location_coords'].values())
center_lat = np.mean([c[0] for c in all_coords])
center_lon = np.mean([c[1] for c in all_coords])
m = folium.Map(location=[center_lat, center_lon], zoom_start=8, tiles='CartoDB positron')
for lid, (lat, lon) in st.session_state['location_coords'].items():
    folium.Marker([lat, lon], popup=f"{lid}: {st.session_state['location_names'].get(lid,'')}", tooltip=str(lid)).add_to(m)
st_folium(m, width=900, height=500)

# -------------------------- Build Distance Matrix & Pack Units --------------------------
st.subheader("Build distance matrix & expand items into pack-units")
loc_ids = sorted([k for k in st.session_state['location_coords'].keys() if k != 'DEPOT'])
all_ids = loc_ids + ['DEPOT']
coords = [st.session_state['location_coords'][lid] for lid in all_ids]
N = len(coords)

dist_mat = np.zeros((N,N),dtype=np.int64)
for i in range(N):
    lat1, lon1 = coords[i]
    for j in range(N):
        lat2, lon2 = coords[j]
        dist_mat[i,j] = int(haversine_distance(lat1, lon1, lat2, lon2))

pack_units = []
for _, row in item_df.iterrows():
    loc = row['location id']
    item_id = row['id']
    L = float(row['length']) * conv
    W = float(row['width']) * conv
    H = float(row['height']) * conv
    weight = float(row['weight'])
    qty = int(row['quantity'])
    stackable = bool(row['stackable'])
    max_stack = int(row['maxStack']) if not pd.isna(row['maxStack']) else 1
    if stackable and max_stack > 1:
        fullstacks = qty // max_stack
        rem = qty % max_stack
        for _ in range(fullstacks):
            pack_units.append({'location id': loc,'item_id': item_id,'length_m': L,'width_m': W,'height_m': H*max_stack,'weight_kg': weight*max_stack,'count': max_stack})
        if rem > 0:
            pack_units.append({'location id': loc,'item_id': item_id,'length_m': L,'width_m': W,'height_m': H*rem,'weight_kg': weight*rem,'count': rem})
    else:
        for _ in range(qty):
            pack_units.append({'location id': loc,'item_id': item_id,'length_m': L,'width_m': W,'height_m': H,'weight_kg': weight,'count': 1})

pack_df = pd.DataFrame(pack_units)
pack_df['volume_m3'] = pack_df['length_m']*pack_df['width_m']*pack_df['height_m']

# -------------------------- Instantiate vehicles --------------------------
st.subheader("Instantiate vehicle instances")
vehicle_instances = []
for _, v in vehicle_df.iterrows():
    v_count = int(v.get('count',1))
    for i in range(v_count):
        inst = {
            'vehicle_type': v.get('vehicle_id', f"veh_{_}"),
            'length_m': float(v['length'])*conv if 'length' in v else 0.0,
            'width_m': float(v['width'])*conv if 'width' in v else 0.0,
            'height_m': float(v['height'])*conv if 'height' in v else 0.0,
            'max_load_kg': float(v.get('max_load',v.get('max_load_kg',0.0))),
            'id': f"{v.get('vehicle_id','veh')}_{i+1}"
        }
        inst['volume_m3'] = inst['length_m']*inst['width_m']*inst['height_m']
        vehicle_instances.append(inst)

# -------------------------- Bin Packing with max check --------------------------
st.subheader("Bin packing (assign packs to vehicles)")

vehicle_state = {v['id']: {
    'remaining_vol': v['volume_m3'],
    'remaining_wt': v['max_load_kg'],
    'vehicle': v,
    'assigned_packs': []
} for v in vehicle_instances}

max_vol = max(v['volume_m3'] for v in vehicle_instances)
max_wt = max(v['max_load_kg'] for v in vehicle_instances)

grouped = pack_df.groupby('location id')
for loc, group in grouped:
    packs = group.sort_values('volume_m3', ascending=False).to_dict('records')
    for p in packs:
        # Check if pack can fit into any vehicle at all
        if p['volume_m3'] > max_vol or p['weight_kg'] > max_wt:
            st.error(f"Item {p['item_id']} at location {loc} is too large/heavy to fit into any truck. Skipping.")
            continue

        placed = False
        v_order = sorted(vehicle_state.items(), key=lambda kv: kv[1]['remaining_vol'], reverse=True)
        for vid, stt in v_order:
            if stt['remaining_vol'] >= p['volume_m3'] and stt['remaining_wt'] >= p['weight_kg']:
                stt['assigned_packs'].append((loc, p))
                stt['remaining_vol'] -= p['volume_m3']
                stt['remaining_wt'] -= p['weight_kg']
                placed = True
                break
        if not placed:
            st.warning(f"Item {p['item_id']} at location {loc} could not fit into any truck with remaining capacity.")

# -------------------------- VRP --------------------------
st.subheader("Create VRP model and solve (OR-Tools)")

location_idx_map = {loc:i for i, loc in enumerate(all_ids)}
num_nodes = len(all_ids)

demand_weight = np.zeros(num_nodes,dtype=int)
demand_volume = np.zeros(num_nodes,dtype=int)
for vid, stt in vehicle_state.items():
    for loc,p in stt['assigned_packs']:
        idx = location_idx_map[loc]
        demand_weight[idx] += int(math.ceil(p['weight_kg']))
        demand_volume[idx] += int(math.ceil(p['volume_m3']*1000))

vehicle_ids = []
vehicle_cap_wt = []
vehicle_cap_vol = []
for vid, stt in vehicle_state.items():
    vehicle_ids.append(vid)
    vehicle_cap_wt.append(int(math.floor(stt['vehicle']['max_load_kg'])))
    vehicle_cap_vol.append(int(math.floor(stt['vehicle']['volume_m3']*1000)))

manager = pywrapcp.RoutingIndexManager(num_nodes,len(vehicle_ids),location_idx_map['DEPOT'])
routing = pywrapcp.RoutingModel(manager)
cost_matrix = dist_mat.tolist()
def distance_callback(i,j):
    ni, nj = manager.IndexToNode(i), manager.IndexToNode(j)
    return int(cost_matrix[ni][nj])
transit_callback_index = routing.RegisterTransitCallback(distance_callback)
routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)

def demand_weight_callback(index):
    node = manager.IndexToNode(index)
    return 0 if node == location_idx_map['DEPOT'] else int(demand_weight[node])
demand_wt_cb = routing.RegisterUnaryTransitCallback(demand_weight_callback)
routing.AddDimensionWithVehicleCapacity(demand_wt_cb,0,vehicle_cap_wt,True,'Weight')

def demand_vol_callback(index):
    node = manager.IndexToNode(index)
    return 0 if node == location_idx_map['DEPOT'] else int(demand_volume[node])
demand_vol_cb = routing.RegisterUnaryTransitCallback(demand_vol_callback)
routing.AddDimensionWithVehicleCapacity(demand_vol_cb,0,vehicle_cap_vol,True,'Volume')

search_params = pywrapcp.DefaultRoutingSearchParameters()
search_params.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC
search_params.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH
search_params.time_limit.seconds = 30

with st.spinner('Solving VRP...'):
    solution = routing.SolveWithParameters(search_params)
if not solution:
    st.error('No VRP solution found')
    st.stop()

solution_routes = {}
solution_distance = {}
for v_idx, vid in enumerate(vehicle_ids):
    index = routing.Start(v_idx)
    route = []
    total_dist = 0
    prev_node = location_idx_map['DEPOT']
    while not routing.IsEnd(index):
        node = manager.IndexToNode(index)
        if node != location_idx_map['DEPOT']:
            loc_id = all_ids[node]
            route.append(loc_id)
            total_dist += dist_mat[prev_node,node]
            prev_node = node
        index = solution.Value(routing.NextVar(index))
    total_dist += dist_mat[prev_node,location_idx_map['DEPOT']]
    solution_routes[vid] = route
    solution_distance[vid] = total_dist/1000.0  # km

st.success('Routing solved')
for v, r in solution_routes.items():
    if r:
        st.write(f"{v} -> {r}, total distance: {solution_distance[v]:.2f} km")

# -------------------------- Visualization --------------------------
st.subheader("Route visualization")
colors = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2','#7f7f7f','#bcbd22']
m = folium.Map(location=[np.mean([c[0] for c in all_coords]), np.mean([c[1] for c in all_coords])], zoom_start=7, tiles='CartoDB positron')

for i,(veh, route_locs) in enumerate(solution_routes.items()):
    if not route_locs:
        continue
    color = colors[i % len(colors)]
    route_coords = [st.session_state['location_coords']['DEPOT']]
    for loc in route_locs:
        lat, lon = st.session_state['location_coords'][loc]
        route_coords.append((lat, lon))
        folium.CircleMarker(location=[lat,lon],radius=6,color=color,fill=True,fill_color=color,fill_opacity=0.9,
                            popup=f"{loc} ({lat:.4f},{lon:.4f})\nVehicle: {veh}", tooltip=str(loc)).add_to(m)
    route_coords.append(st.session_state['location_coords']['DEPOT'])
    folium.PolyLine(route_coords,color=color,weight=3,opacity=0.8).add_to(m)
    folium.map.Marker(route_coords[1], icon=folium.DivIcon(html=f"<div style='font-size:12pt;color:{color};font-weight:bold'>{veh}</div>")).add_to(m)

# depot
dlat, dlon = st.session_state['location_coords']['DEPOT']
folium.Marker([dlat,dlon], popup="DEPOT", tooltip="DEPOT", icon=folium.Icon(color='black',icon='home')).add_to(m)

st_folium(m,width=900,height=600)

# -------------------------- Export --------------------------
st.subheader('Export results')
rows = []
for vid, stt in vehicle_state.items():
    for loc, p in stt['assigned_packs']:
        rows.append({'vehicle_id': vid,'location': loc,'item_id': p['item_id'],'count': p['count'],'weight_kg': p['weight_kg'],'volume_m3': p['volume_m3']})
assign_df = pd.DataFrame(rows)
if not assign_df.empty:
    csv = assign_df.to_csv(index=False).encode('utf-8')
    st.download_button('Download assignments CSV', data=csv, file_name='assignments.csv', mime='text/csv')

st.info('Page 6 complete. Copy this file into your Streamlit multipage app.')

